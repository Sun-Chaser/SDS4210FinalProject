---
title: "4210FinalProjectDataAggregationAndClean"
author: "Jack Yang"
date: "`r Sys.Date()`"
output: pdf_document
---

#Setup and Library Loading Chunk

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(httr)
library(jsonlite)
library(dplyr)
library(tibble)
library(purrr)
library(rlang)
library(tidyr)
library(stringr)
library(ggplot2)
library(scales)
library(KFAS)
library(MARSS)
library(zoo)
library(scales)

UA <- "Brian Wei, Honghao Yang, Justin Choi, Tengis Kelley | b.j.wei@wustl.edu, honghao@wustl.edu, c.younghwan@wustl.edu, k.tengis@wustl.edu | (Class project; R script)"
```

#Import Raw Dataset

```{r}
get_frame <- function(concept = "NetIncomeLoss", unit = "USD", frame = "CY2024Q4") {
  url <- sprintf("https://data.sec.gov/api/xbrl/frames/%s/%s/%s.json",
                 paste0("us-gaap/", concept), unit, frame)
  print(url)
  r <- GET(url, add_headers(`User-Agent` = UA))
  stop_for_status(r)
  jj <- fromJSON(content(r, "text", encoding = "UTF-8"), simplifyVector = TRUE)

  df <- as_tibble(jj$data)
  
  df <- subset(df, select = -c(accn, start, end))

  # Ensure optional columns exist (fill with NA if missing)
  optional <- c("entityName","loc", "val", "cik")
  for (nm in setdiff(optional, names(df))) df[[nm]] <- NA
  
  return(df[])
}

# Make frame keys like "CY2024Q1"..."CY2024Q4" for a year range
make_quarter_frames <- function(start_year, end_year) {
  yrs <- seq.int(start_year, end_year)
  unlist(lapply(yrs, function(y) sprintf("CY%dQ%d", y, 1:4)), use.names = FALSE)
}

# Fetch all frames for a concept/unit over a year range (inclusive)
fetch_frames_range <- function(start_year, end_year,
                               concept = "NetIncomeLoss",
                               unit = "USD",
                               sleep = 0.2) {
  frames <- make_quarter_frames(start_year, end_year)
  out <- vector("list", length(frames))
  names(out) <- sub("^CY", "", frames)        # e.g., "2024Q4"

  for (i in seq_along(frames)) {
    fr <- frames[i]
    out[[i]] <- tryCatch(
      {
        Sys.sleep(sleep)                       # be polite to SEC
        get_frame(concept, unit, fr)
      },
      error = function(e) {
        message("Skipped ", fr, " (", conditionMessage(e), ")")
        NULL
      }
    )
  }
  out
}
```

# Pull NetIncomeLoss for all quarters 2008–2024

```{r, cache=TRUE}
all_22_24 <- fetch_frames_range(2008, 2024, concept = "NetIncomeLoss", unit = "USD")
```
# Glue quarter dataset in a single large dataframe by entityName

```{r}
join_frames_wide <- function(frames_list,
                                       id_cols   = c("cik","entityName", "loc"),
                                       value_col = "val",
                                       keep_cols = c("cik")) {
  stopifnot(length(frames_list) > 0)

  cleaned <- imap(frames_list, function(df, lab) {
    if (is.null(df) || !nrow(df)) return(NULL)

    # Only use IDs/keep columns that are present in this df
    present_id   <- intersect(id_cols,   names(df))
    present_keep <- intersect(keep_cols, names(df))
    if (!length(present_id)) {
      warning("No id_cols found in one frame; skipping it.")
      return(NULL)
    }

    df %>%
      select(any_of(c(present_id, present_keep, value_col))) %>%
      group_by(across(any_of(present_id))) %>%
      summarise(
        across(any_of(present_keep), ~{
          u <- unique(na.omit(.x))
          if (length(u)) u[1] else dplyr::first(.x)
        }, .names = "{.col}"),
        !!lab := dplyr::first(.data[[value_col]]),
        .groups = "drop"
      )
  }) %>% compact()

  # Full-join everything on the full id_cols set (missing IDs will be created as NA)
  out <- reduce(cleaned, full_join, by = id_cols)

  out
}
```

```{r}
wide <- join_frames_wide(all_22_24, id_cols   = c("cik","entityName", "loc"),
                                   value_col = "val",
                                   keep_cols = c("cik")) 
head(wide)
```

# Filter out companies with too many NAs (closed company)

```{r}
filter_by_missingness <- function(wide,
                                  quarter_regex = "^\\d{4}Q[1-4]$",
                                  max_na = 17,            # ≤25% of 68
                                  require_recent = 4) {   # last 4 quarters must be non-NA
  qcols <- grep(quarter_regex, names(wide), value = TRUE)
  stopifnot(length(qcols) > 0)

  summ <- wide %>%
    mutate(
      n_quarters  = length(qcols),
      n_na        = rowSums(is.na(pick(all_of(qcols)))),
      n_non_na    = n_quarters - n_na,
      pct_missing = n_na / n_quarters
    )

  recent_ok <- summ %>%
    transmute(recent_na = rowSums(is.na(pick(all_of(tail(qcols, require_recent)))))) %>%
    pull(recent_na) == 0

  cleaned <- summ %>%
    filter(n_na <= max_na & recent_ok) %>%
    select(-n_quarters, -n_na, -n_non_na, -pct_missing)  # drop helper cols if you like

  list(
    data    = cleaned,
    summary = summ %>% select(any_of(c("cik","entityName")), n_non_na, n_na, pct_missing),
    kept    = nrow(cleaned),
    dropped = nrow(wide) - nrow(cleaned)
  )
}
```

```{r}
clean_data_result <- filter_by_missingness(wide, max_na = 34, require_recent = 1)

cleaned_data  <- clean_data_result$data
head(cleaned_data)
head(clean_data_result$summary)          # NA counts per firm
clean_data_result$kept; clean_data_result$dropped      # how many kept/dropped
```


# Fetch corresponding Standard Industrial Classification for each company
```{r}
pad_cik <- function(x) sprintf("%010d", as.integer(x))

get_sic_from_submissions <- function(cik) {
  url <- sprintf("https://data.sec.gov/submissions/CIK%s.json", pad_cik(cik))
  r <- GET(url, add_headers(`User-Agent` = UA))
  if (http_error(r)) return(tibble(cik = pad_cik(cik), sic = NA_integer_, sicDescription = NA_character_))
  jj <- fromJSON(content(r, "text", encoding = "UTF-8"))
  tibble(
    cik = pad_cik(cik),
    sic = suppressWarnings(as.integer(jj$sic)),
    sicDescription = jj$sicDescription %||% NA_character_
  )
}

# Vectorized for many CIKs (rate-limit politely)
get_sic_many <- function(ciks, sleep = 0.2) {
  map_dfr(unique(ciks), ~{ Sys.sleep(sleep); get_sic_from_submissions(.x) })
}
```


```{r, cache=TRUE}
sic_map <- get_sic_many(cleaned_data$cik)
```

# Map the sic into the dataframe

```{r}
# 1) Clean both tables’ CIKs to the same *character* format (zero-padded 10)
cleaned_data <- cleaned_data %>%
  mutate(cik = pad_cik(cik)) %>%
  filter(!is.na(cik) & cik != "NA")

sic_map_clean <- sic_map %>%
  mutate(cik = pad_cik(cik)) %>%
  filter(!is.na(cik) & cik != "NA")

# 2) Deduplicate sic_map so each CIK appears once (prevents row explosion on join)
# If you have an “accepted” or date column, use it to pick the latest per CIK.
sic_map_clean <- sic_map_clean %>%
  arrange(cik) %>%                          # or arrange(cik, accepted)
  distinct(cik, .keep_all = TRUE) %>%
  select(cik, sic, dplyr::any_of("sicDescription"))  # keep only what you need

# 3) Join
cleaned_data <- cleaned_data %>%
  left_join(sic_map_clean, by = "cik")

# 4) Quick sanity checks
stopifnot(is.character(cleaned_data$cik))
cat("Rows after join:", nrow(cleaned_data), "\n")
cat("Missing SIC after join:", sum(is.na(cleaned_data$sic)), "\n")
```



# Dataset 1: Temporal Data

```{r}
order_quarters <- function(qnames) {
  qnames[order(as.integer(substr(qnames, 1, 4)),
               as.integer(sub(".*Q", "", qnames)))]
}

sic_to_division <- function(sic) {
  s <- suppressWarnings(as.integer(sic))
  dplyr::case_when(
    is.na(s) ~ "Unknown",
    s >= 100  & s <= 999   ~ "Agriculture/Forestry/Fishing",
    s >= 1000 & s <= 1499  ~ "Mining",
    s >= 1500 & s <= 1799  ~ "Construction",
    s >= 2000 & s <= 3999  ~ "Manufacturing",
    s >= 4000 & s <= 4999  ~ "Transportation/Public Utilities",
    s >= 5000 & s <= 5199  ~ "Wholesale Trade",
    s >= 5200 & s <= 5999  ~ "Retail Trade",
    s >= 6000 & s <= 6799  ~ "Finance/Insurance/Real Estate",
    s >= 7000 & s <= 8999  ~ "Services",
    s >= 9100 & s <= 9729  ~ "Public Administration",
    s >= 9900 & s <= 9999  ~ "Nonclassifiable",
    TRUE ~ "Other"
  )
}

make_temporal_df <- function(cleaned_data,
                             quarter_regex = "^\\d{4}Q[1-4]$",
                             noise_sd = 1,
                             seed = NULL,
                             id_cols = c("cik","entityName","sic")) {

  qcols <- grep(quarter_regex, names(cleaned_data), value = TRUE)
  stopifnot(length(qcols) > 0)
  qcols <- order_quarters(qcols)

  long <- cleaned_data %>%
    select(any_of(c(id_cols, qcols))) %>%
    pivot_longer(all_of(qcols), names_to = "quarter", values_to = "y") %>%
    mutate(
      year = as.integer(substr(.data$quarter, 1, 4)),
      qtr  = as.integer(sub(".*Q", "", .data$quarter))
    ) %>%
    arrange(.data$year, .data$qtr)

  uniq_q <- long %>%
    distinct(.data$quarter, .data$year, .data$qtr) %>%
    arrange(.data$year, .data$qtr) %>%
    mutate(t_index = row_number())

  long <- long %>% left_join(uniq_q, by = c("quarter","year","qtr"))

  if (!is.null(seed)) set.seed(seed)
  long <- long %>%
    group_by(.data$quarter) %>%
    mutate(x_latent = rnorm(n(), mean = first(.data$t_index), sd = noise_sd)) %>%
    ungroup() %>%
    mutate(
      sic_division = sic_to_division(.data$sic)
    )

  # one-hot SIC division indicators
  dummies <- model.matrix(~ factor(long$sic_division) - 1)
  colnames(dummies) <- sub("^factor\\(long\\$sic_division\\)", "ind_", colnames(dummies))
  dummies <- as.data.frame(dummies)

  bind_cols(long, dummies) %>%
    select(any_of(id_cols),
           sic_division, quarter, year, qtr, t_index, x_latent, y,
           starts_with("ind_")) %>%
    arrange(.data$cik, .data$year, .data$qtr)
}
```

```{r}
temporal_df <- make_temporal_df(cleaned_data, noise_sd = 1, seed = 4210)
head(temporal_df)
table(temporal_df$sic_division)
```
# Initial Visualization

```{r}
plot_temporal_scatter <- function(
  df,
  industry_cols = c("sic_division","industry","industry_type"),
  x_col = "x_latent",
  y_col = "y",
  point_alpha = 0.6,
  point_size  = 1.8,
  legend_bottom = TRUE
) {
  # choose the first industry column that exists
  ind_col <- industry_cols[industry_cols %in% names(df)][1]
  if (is.na(ind_col)) stop("No industry column found. Looked for: ", paste(industry_cols, collapse=", "))

  # filter & factor
  plot_df <- df %>%
    filter(!is.na(.data[[x_col]]), !is.na(.data[[y_col]]), !is.na(.data[[ind_col]])) %>%
    mutate(!!ind_col := factor(.data[[ind_col]]))

  # theme tweak
  base_theme <- theme_minimal(base_size = 12) +
    theme(legend.position = if (legend_bottom) "bottom" else "right")

  # Normal scale
  p_linear <- ggplot(plot_df, aes(x = .data[[x_col]], y = .data[[y_col]], color = .data[[ind_col]])) +
    geom_point(alpha = point_alpha, size = point_size) +
    labs(x = "Latent time index (noisy)", y = "Gross income", color = "Industry") +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    base_theme

  # Log scale (ensure domain for log1p)
  plot_df_log <- filter(plot_df, .data[[y_col]] > -1)
  p_log <- ggplot(plot_df_log, aes(x = .data[[x_col]], y = .data[[y_col]], color = .data[[ind_col]])) +
    geom_point(alpha = point_alpha, size = point_size) +
    scale_y_continuous(trans = "log1p",
                       labels = label_number(scale_cut = cut_short_scale())) +
    labs(x = "Latent time index (noisy)", y = "Gross income (log1p)", color = "Industry") +
    base_theme

  list(linear = p_linear, log = p_log)
}
```

```{r}
# ---- usage ----
plots <- plot_temporal_scatter(temporal_df)
plots$linear
plots$log
```


# Make classified dataset using CIK
```{r}
sic_to_division <- function(s) {
  s <- suppressWarnings(as.integer(s))
  dplyr::case_when(
    is.na(s) ~ "Unknown",
    s>=100  & s<=999   ~ "Agriculture/Forestry/Fishing",
    s>=1000 & s<=1499  ~ "Mining",
    s>=1500 & s<=1799  ~ "Construction",
    s>=2000 & s<=3999  ~ "Manufacturing",
    s>=4000 & s<=4999  ~ "Transportation/Public Utilities",
    s>=5000 & s<=5199  ~ "Wholesale Trade",
    s>=5200 & s<=5999  ~ "Retail Trade",
    s>=6000 & s<=6799  ~ "Finance/Insurance/Real Estate",
    s>=7000 & s<=8999  ~ "Services",
    s>=9100 & s<=9729  ~ "Public Administration",
    s>=9900 & s<=9999  ~ "Nonclassifiable",
    TRUE ~ "Other"
  )
}

# --- Build per-company CI; x = SIC + Normal noise ---
make_company_ci_df <- function(cleaned_data,
                               quarter_regex = "^\\d{4}Q[1-4]$",
                               noise_sd = 1,
                               seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  qcols <- grep(quarter_regex, names(cleaned_data), value = TRUE)
  stopifnot(length(qcols) > 0)

  long <- cleaned_data %>%
    select(cik, entityName, sic, all_of(qcols)) %>%
    pivot_longer(all_of(qcols), names_to = "quarter", values_to = "gross_income") %>%
    filter(!is.na(gross_income))

  ci <- long %>%
    group_by(cik, entityName, sic) %>%
    summarise(
      n      = n(),
      mean_y = mean(gross_income),
      sd_y   = sd(gross_income),
      se_y   = sd_y / sqrt(n),
      y_lo   = mean_y - 1.96*se_y,
      y_hi   = mean_y + 1.96*se_y,
      .groups = "drop"
    ) %>%
    mutate(
      sic_num      = suppressWarnings(as.integer(sic)),
      sic_num      = ifelse(is.na(sic_num), as.numeric(factor(sic)), sic_num),
      x            = sic_num + rnorm(n(), 0, noise_sd),
      sic_division = sic_to_division(sic)
    )

  ci
}
```

```{r}
company_ci <- make_company_ci_df(cleaned_data, noise_sd = 1, seed = 4210)
head(company_ci)
```

# Plot visualization
```{r}
plot_company_ci <- function(
  df,
  x_col   = "x",
  mean_col= "mean_y",
  lo_col  = "y_lo",
  hi_col  = "y_hi",
  color_cols = c("sic_division","industry","industry_type"),
  point_alpha = 0.7,
  point_size  = 1.8,
  legend_bottom = TRUE
){
  # choose color column
  color_col <- color_cols[color_cols %in% names(df)][1]
  if (is.na(color_col)) stop("No industry column found. Looked for: ", paste(color_cols, collapse=", "))

  # base filtered data
  plot_df <- df %>%
    filter(!is.na(.data[[mean_col]]),
           !is.na(.data[[x_col]]),
           !is.na(.data[[color_col]])) %>%
    mutate(!!color_col := factor(.data[[color_col]]))

  base_theme <- theme_minimal(base_size = 12) +
    theme(legend.position = if (legend_bottom) "bottom" else "right")

  # Linear y
  p_linear <- ggplot(plot_df, aes(x = .data[[x_col]], y = .data[[mean_col]], color = .data[[color_col]])) +
    geom_point(alpha = point_alpha, size = point_size) +
    geom_errorbar(aes(ymin = .data[[lo_col]], ymax = .data[[hi_col]]), width = 0) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    labs(x = "SIC (with Normal noise)", y = "Gross income (mean, 95% CI)", color = "Industry division") +
    base_theme

  # Log1p y (keep valid domain)
  plot_df_log <- plot_df %>% filter(.data[[hi_col]] > -1)
  p_log <- ggplot(plot_df_log, aes(x = .data[[x_col]], y = .data[[mean_col]], color = .data[[color_col]])) +
    geom_point(alpha = point_alpha, size = point_size) +
    geom_errorbar(aes(ymin = .data[[lo_col]], ymax = .data[[hi_col]]), width = 0) +
    scale_y_continuous(trans = "log1p", labels = label_number(scale_cut = cut_short_scale())) +
    labs(x = "SIC (with Normal noise)", y = "Gross income (mean, 95% CI) — log1p", color = "Industry division") +
    base_theme

  list(linear = p_linear, log = p_log)
}

```

```{r}
plots_ci <- plot_company_ci(company_ci)
plots_ci$linear
plots_ci$log
```


# EM algorithm with Kalman Filter
```{r}
# Quarter column finder
quarter_cols <- function(df, regex = "^\\d{4}Q[1-4]$") {
  qs <- grep(regex, names(df), value = TRUE)
  qs[order(as.integer(substr(qs, 1, 4)),
           as.integer(sub(".*Q", "", qs)))]
}

# Fallbacks (always return length(y))
fallback_impute <- function(y) {
  # 1) LOCF/ NOCB
  y_l <- na.locf(y, na.rm = FALSE)
  y_ln <- na.locf(y_l, fromLast = TRUE, na.rm = FALSE)
  # 2) If still NA (all-missing series), use 0
  y_ln[is.na(y_ln)] <- 0
  y_ln
}

# EM + Kalman for ONE series on asinh scale, with hard fallbacks
em_impute_series_asinh <- function(y, maxit = 200, asinh_scale = 1) {
  n <- length(y)
  z <- asinh(y / asinh_scale)

  # If <2 non-missing, return flat mean (or zeros if all NA)
  if (sum(is.finite(z)) < 2) {
    mu <- if (any(is.finite(z))) mean(z[is.finite(z)]) else 0
    return(list(z_hat = rep(mu, n)))
  }

  yt <- matrix(z, nrow = 1)
  mod <- list(
    Z = matrix(1), A = "zero",
    R = matrix("r"),
    B = matrix(1), U = "zero",
    Q = matrix("q"),
    x0 = "unequal"
  )

  fit <- tryCatch(
    MARSS(yt, model = mod,
          control = list(maxit = maxit, conv.test.slope.tol = 1e-4),
          silent = TRUE),
    error = function(e) NULL
  )

  if (is.null(fit) || !is.list(fit) || is.null(fit$par) ) {
    # MARSS failed → fallback to smooth LOCF on original scale
    y_imp <- fallback_impute(y)
    z_hat <- asinh(y_imp / asinh_scale)
    return(list(z_hat = z_hat))
  }

  z_hat <- tryCatch(
    as.numeric(fitted(fit, type = "ytT")$ytT),
    error = function(e) NULL
  )

  # Final safety: always return length n
  if (is.null(z_hat) || length(z_hat) != n) {
    y_imp <- fallback_impute(y)
    z_hat <- asinh(y_imp / asinh_scale)
  }
  list(z_hat = z_hat)
}

# Main: impute all companies in cleaned_data (wide quarters)
kalman_em_impute_marss <- function(cleaned_data,
                                   q_regex = "^\\d{4}Q[1-4]$",
                                   maxit = 200,
                                   asinh_scale = 1) {
  qs <- quarter_cols(cleaned_data, q_regex)
  stopifnot(length(qs) > 0)

  X <- as.matrix(cleaned_data[, qs, drop = FALSE])
  storage.mode(X) <- "double"

  Zhat <- matrix(NA_real_, nrow = nrow(X), ncol = ncol(X))

  for (i in seq_len(nrow(X))) {
    res <- em_impute_series_asinh(X[i, ], maxit = maxit, asinh_scale = asinh_scale)
    # guarantee correct length before assignment
    if (length(res$z_hat) != ncol(X)) {
      # last-resort guard (should not happen)
      res$z_hat <- rep(mean(asinh(X[i, ]/asinh_scale), na.rm = TRUE) %||% 0, ncol(X))
    }
    Zhat[i, ] <- res$z_hat
  }

  # Back-transform to original scale
  Yimp <- asinh_scale * sinh(Zhat)

  out <- cleaned_data
  out[, qs] <- Yimp
  out
}

```


```{r}
imputed_wide <- kalman_em_impute_marss(cleaned_data, maxit = 200, asinh_scale = 1)
```

```{r}
temporal_df_full  <- make_temporal_df(imputed_wide, noise_sd = 1, seed = 4210)
company_ci_full   <- make_company_ci_df(imputed_wide, noise_sd = 1, seed = 4210)
```

```{r}
# ---- usage ----
plots_full <- plot_temporal_scatter(temporal_df_full)
plots_full$linear
plots_full$log
```
```{r}
plots_ci_full <- plot_company_ci(company_ci_full)
plots_ci_full$linear
plots_ci_full$log
```


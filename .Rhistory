# Set up the result list
results_list <- vector("list", nrow(grid))
# Hyperparameter tuning
for (i in seq_len(nrow(grid))) {
# Get the setting
n.trees_i <- grid$n.trees[i]
interaction.depth_i <- grid$interaction.depth[i]
shrinkage_i <- grid$shrinkage[i]
n.minobsinnode_i <- grid$n.minobsinnode[i]
# Train the model
gbm_fit <- gbm(
formula = target_bin ~ .,
data = train_gbm,
distribution = "bernoulli",
n.trees = n.trees_i,          # cap; early-stop via OOB
interaction.depth = interaction.depth_i,
shrinkage = shrinkage_i,
n.minobsinnode = n.minobsinnode_i,
bag.fraction = bag.fraction,
cv.folds = 0,
keep.data = FALSE,
verbose = FALSE
)
# OOB-based early stopping
best_iter <- gbm.perf(gbm_fit, method = "OOB", plot.it = FALSE)
# Predicted probabilities for positive class
prob_hat <- predict(
gbm_fit,
newdata = x_test,
n.trees = best_iter,
type = "response"
)
# Class predictions via 0.5 threshold
class_hat <- ifelse(prob_hat >= 0.5, pos_level, levels(test$target)[1])
class_hat <- factor(class_hat, levels = levels(test$target))
# Resulting metrics
results_list[[i]] <- data.frame(
n.trees = n.trees_i,
interaction.depth = interaction.depth_i,
shrinkage = shrinkage_i,
n.minobsinnode = n.minobsinnode_i,
best_iter = best_iter,
acc = acc(test$target, class_hat),
auc = auc_(test$target, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best first)
results[order(results$auc), ]
}
# BART classification hyperparameter tuning and evaluation
bart_grid_search_class <- function(train,
test,
ntree_values,
k_values,
ndpost = 1000,
nskip = 1000) {
# Sanity check for factor levels
train$target <- factor(train$target)
test$target  <- factor(test$target, levels = levels(train$target))
stopifnot(length(levels(train$target)) == 2)
# Binary 0/1 outcome for gbm (1 = positive = 2nd level)
pos_level <- levels(train$target)[2]
y_train <- ifelse(train$target == pos_level, 1, 0)
x_train <- subset(train, select = -target)
x_test <- subset(test,  select = -target)
# Set up hyperparameter grid
grid <- expand.grid(
ntree = ntree_values,
k = k_values
)
# Set up result list
results_list <- vector("list", nrow(grid))
# Hyperparameter tuning
for (i in seq_len(nrow(grid))) {
# Get the setting
ntree_i <- grid$ntree[i]
k_i <- grid$k[i]
# Fit the model
fit <- dbarts::bart(
x.train = x_train,
y.train = y_train,
x.test = x_test,
ntree = ntree_i,
k = k_i,
ndpost = ndpost,
nskip = nskip,
verbose = FALSE,
keeptrees = TRUE
)
# Get posterior samples
prob_samples <- pnorm(fit$yhat.test)
prob_hat <- colMeans(prob_samples)  # posterior mean
# Class predictions using 0.5 threshold
class_hat <- ifelse(prob_hat >= 0.5, pos_level, levels(test$target)[1])
class_hat <- factor(class_hat, levels = levels(test$target))
# Resulting metrics
results_list[[i]] <- data.frame(
ntree = ntree_i,
k = k_i,
acc = acc(test$target, class_hat),
auc = auc_(test$target, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best first)
results[order(results$auc), ]
}
# Train and tune Random Forest Model
p_rf <- ncol(regA_train) - 1
set.seed(123)
rf_results <- rf_grid_search(
train = regA_train,
test = regA_test,
mtry_values = c(2, floor(sqrt(p)), 10),
nodesize_values = c(1, 5, 10),
ntree = 500
)
# highlight best + top 3
cat("Best configuration (by rmse):\n")
print(rf_results[1, ])
cat("\nTop 3 configurations (by rmse):\n")
print(head(rf_results, 3))
# Train and tune GBM Model
set.seed(123)
gbm_kfold_results <- gbm_grid_search (
train = regA_train,
test = regA_test,
n.trees.values = c(2000, 4000, 6000),
interaction.depth.values = c(2, 3, 4),
shrinkage.values = c(0.01, 0.05),
n.minobsinnode.values = c(5, 10),
bag.fraction = 0.7
)
# highlight best + top 3
cat("Best configuration (by rmse):\n")
print(gbm_kfold_results[1, ])
cat("\nTop 3 configurations (by rmse):\n")
print(head(gbm_kfold_results, 3))
# Train and tune BART Model
set.seed(123)
bart_results <- bart_grid_search (
train = regA_train,
test = regA_test,
ntree_values = c(50, 100, 200),
k_values = c(1, 2, 3),
ndpost = 1000,
nskip = 1000
)
# highlight best + top 3
cat("Best configuration (by rmse):\n")
print(bart_results[1, ])
cat("\nTop 3 configurations (by rmse):\n")
print(head(bart_results, 3))
View(cls_test)
# Create is_setosa column for classification
cls_train$is_setosa <- ifelse(cls_train$target == "setosa", 1, 0)
cls_test$is_setosa <- ifelse(cls_test$target == "setosa", 1, 0)
?setdiff
# Random forest classification hyperparameter tuning and evaluation
rf_grid_search_class <- function(train,
test,
mtry_values,
nodesize_values,
ntree = 500) {
# Sanity check for factor level
train$target <- factor(train$is_setosa)
test$target <- factor(test$is_setosa, levels = levels(train$is_setosa))
# Set up hyperparameter grid
grid <- expand.grid(
mtry = mtry_values,
nodesize = nodesize_values
)
# Set up result list
results_list <- vector("list", nrow(grid))
# Hyperparameter tuning
for (i in seq_len(nrow(grid))) {
# Get the setting
mtry_i <- grid$mtry[i]
nodesize_i <- grid$nodesize[i]
# Fit the model
rf_fit <- randomForest(
formula = target ~ .,
data = train,
ntree = ntree,
mtry = mtry_i,
nodesize = nodesize_i,
importance = TRUE
)
# Class predictions
class_hat <- predict(rf_fit, newdata = test, type = "response")
# Probabilities for the positive class (2nd level)
prob_mat <- predict(rf_fit, newdata = test, type = "prob")
prob_hat <- prob_mat[, 2]
# Resulting metrics
results_list[[i]] <- data.frame(
mtry = mtry_i,
nodesize = nodesize_i,
acc = acc(test$target, class_hat),
auc = auc_(test$target, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best at top)
results[order(results$auc), ]
}
# Train and tune Random Forest Model
p_rf <- ncol(regA_train) - 1
set.seed(123)
rf_results <- rf_grid_search(
train = regA_train,
test = regA_test,
mtry_values = c(2, floor(sqrt(p)), 10),
nodesize_values = c(1, 5, 10),
ntree = 500
)
# highlight best + top 3
cat("Best configuration (by rmse):\n")
print(rf_results[1, ])
cat("\nTop 3 configurations (by rmse):\n")
print(head(rf_results, 3))
# Create is_setosa column for classification
cls_train$is_setosa <- ifelse(cls_train$target == "setosa", 1, 0)
cls_test$is_setosa <- ifelse(cls_test$target == "setosa", 1, 0)
# Train and tune Random Forest Model
p_rf <- ncol(cls_train) - 1
set.seed(123)
grid_results_class <- rf_grid_search_class (
train = cls_train,
test = cls_test,
mtry_values = c(2, floor(sqrt(p)), 10),
nodesize_values = c(1, 5, 10),
ntree = 500
)
# Random forest classification hyperparameter tuning and evaluation
rf_grid_search_class <- function(train,
test,
mtry_values,
nodesize_values,
ntree = 500) {
# Create target as factor, drop label helper from features
train$target <- factor(train$is_setosa, levels = c(0, 1))
test$target  <- factor(test$is_setosa,  levels = c(0, 1))
train_rf <- subset(train, select = -is_setosa)
test_rf  <- subset(test,  select = -is_setosa)
# Hyperparameter grid
grid <- expand.grid(
mtry     = mtry_values,
nodesize = nodesize_values
)
results_list <- vector("list", nrow(grid))
for (i in seq_len(nrow(grid))) {
mtry_i     <- grid$mtry[i]
nodesize_i <- grid$nodesize[i]
rf_fit <- randomForest(
formula    = target ~ .,
data       = train_rf,
ntree      = ntree,
mtry       = mtry_i,
nodesize   = nodesize_i,
importance = TRUE
)
# Predictions on test
class_hat <- predict(rf_fit, newdata = test_rf, type = "response")
prob_mat  <- predict(rf_fit, newdata = test_rf, type = "prob")
prob_hat  <- prob_mat[, 2]   # positive class = level "1"
results_list[[i]] <- data.frame(
mtry     = mtry_i,
nodesize = nodesize_i,
acc      = acc(test_rf$target, class_hat),
auc      = auc_(test_rf$target, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best at top) – use minus for descending
results[order(-results$auc), ]
}
# Random forest classification hyperparameter tuning and evaluation
rf_grid_search_class <- function(train,
test,
mtry_values,
nodesize_values,
ntree = 500) {
# Create target as factor, drop label helper from features
train$target <- factor(train$is_setosa, levels = c(0, 1))
test$target  <- factor(test$is_setosa,  levels = c(0, 1))
train_rf <- subset(train, select = -is_setosa)
test_rf  <- subset(test,  select = -is_setosa)
# Hyperparameter grid
grid <- expand.grid(
mtry     = mtry_values,
nodesize = nodesize_values
)
results_list <- vector("list", nrow(grid))
for (i in seq_len(nrow(grid))) {
mtry_i     <- grid$mtry[i]
nodesize_i <- grid$nodesize[i]
rf_fit <- randomForest(
formula    = target ~ .,
data       = train_rf,
ntree      = ntree,
mtry       = mtry_i,
nodesize   = nodesize_i,
importance = TRUE
)
# Predictions on test
class_hat <- predict(rf_fit, newdata = test_rf, type = "response")
prob_mat  <- predict(rf_fit, newdata = test_rf, type = "prob")
prob_hat  <- prob_mat[, 2]   # positive class = level "1"
results_list[[i]] <- data.frame(
mtry     = mtry_i,
nodesize = nodesize_i,
acc      = acc(test_rf$target, class_hat),
auc      = auc_(test_rf$target, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best at top) – use minus for descending
results[order(-results$auc), ]
}
# Train and tune Random Forest Model
p_rf <- ncol(cls_train) - 1
set.seed(123)
grid_results_class <- rf_grid_search_class (
train = cls_train,
test = cls_test,
mtry_values = c(2, floor(sqrt(p)), 10),
nodesize_values = c(1, 5, 10),
ntree = 500
)
# highlight best + top 3
cat("Best configuration (by auc):\n")
print(grid_results_class[1, ])
cat("\nTop 3 configurations (by auc):\n")
print(head(grid_results_class, 3))
# GBM classification hyperparameter tuning and evaluation
gbm_grid_search_class <- function(train,
test,
n.trees.values,
interaction.depth.values,
shrinkage.values,
n.minobsinnode.values,
bag.fraction = 0.7) {
# underlying 0/1 label is in is_setosa
train$target <- factor(train$is_setosa, levels = c(0, 1))
test$target  <- factor(test$is_setosa,  levels = levels(train$target))
stopifnot(length(levels(train$target)) == 2)
# truth as factor (for acc / auc_)
truth <- test$target
# positive class = 2nd level (i.e., "1")
pos_level <- levels(train$target)[2]
# numeric 0/1 outcome for gbm (1 = positive class)
y_train <- ifelse(train$target == pos_level, 1, 0)
# predictor names: drop the label columns
feature_names <- setdiff(names(train), c("target", "is_setosa"))
# Training data for gbm: numeric response + predictors
train_gbm <- data.frame(
target_bin = y_train,
train[, feature_names, drop = FALSE]
)
# Testing data for GBM: same feature set (no target_bin)
x_test <- test[, feature_names, drop = FALSE]
# Set up hyperparameter grid
grid <- expand.grid(
n.trees           = n.trees.values,
interaction.depth = interaction.depth.values,
shrinkage         = shrinkage.values,
n.minobsinnode    = n.minobsinnode.values
)
# Set up the result list
results_list <- vector("list", nrow(grid))
# Hyperparameter tuning
for (i in seq_len(nrow(grid))) {
# Get the setting
n.trees_i           <- grid$n.trees[i]
interaction.depth_i <- grid$interaction.depth[i]
shrinkage_i         <- grid$shrinkage[i]
n.minobsinnode_i    <- grid$n.minobsinnode[i]
# Train the model
gbm_fit <- gbm(
formula           = target_bin ~ .,
data              = train_gbm,
distribution      = "bernoulli",
n.trees           = n.trees_i,          # cap; early-stop via OOB
interaction.depth = interaction.depth_i,
shrinkage         = shrinkage_i,
n.minobsinnode    = n.minobsinnode_i,
bag.fraction      = bag.fraction,
cv.folds          = 0,
keep.data         = FALSE,
verbose           = FALSE
)
# OOB-based early stopping
best_iter <- gbm.perf(gbm_fit, method = "OOB", plot.it = FALSE)
# Predicted probabilities for positive class
prob_hat <- predict(
gbm_fit,
newdata = x_test,
n.trees = best_iter,
type    = "response"   # for bernoulli => probabilities
)
# Class predictions via 0.5 threshold
class_hat <- ifelse(prob_hat >= 0.5, pos_level, levels(truth)[1])
class_hat <- factor(class_hat, levels = levels(truth))
# Resulting metrics (acc / auc_ expect factor truth)
results_list[[i]] <- data.frame(
n.trees           = n.trees_i,
interaction.depth = interaction.depth_i,
shrinkage         = shrinkage_i,
n.minobsinnode    = n.minobsinnode_i,
best_iter         = best_iter,
acc               = acc(truth, class_hat),
auc               = auc_(truth, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best first)
results[order(-results$auc), ]
}
# Train and tune GBM Model
set.seed(123)
gbm_results_class <- gbm_grid_search_class (
train = cls_train,
test = cls_test,
n.trees.values = c(2000, 4000),
interaction.depth.values = c(2, 3),
shrinkage.values = c(0.01, 0.05),
n.minobsinnode.values  = c(5, 10),
bag.fraction = 0.7
)
# highlight best + top 3
cat("Best configuration (by auc):\n")
print(gbm_results_class[1, ])
cat("\nTop 3 configurations (by auc):\n")
print(head(gbm_results_class, 3))
# BART classification hyperparameter tuning and evaluation
bart_grid_search_class <- function(train,
test,
ntree_values,
k_values,
ndpost = 1000,
nskip  = 1000) {
# ---- Create factor targets for metrics ----
# underlying 0/1 label is in is_setosa
train$target <- factor(train$is_setosa, levels = c(0, 1))
test$target  <- factor(test$is_setosa,  levels = levels(train$target))
stopifnot(length(levels(train$target)) == 2)
truth     <- test$target           # factor for acc / auc_
pos_level <- levels(train$target)[2]
# BART wants 0/1 numeric; 1 = positive (2nd level)
y_train <- ifelse(train$target == pos_level, 1, 0)
# Predictors: drop label columns
x_train <- subset(train, select = -c(target, is_setosa))
x_test  <- subset(test,  select = -c(target, is_setosa))
# Set up hyperparameter grid
grid <- expand.grid(
ntree = ntree_values,
k     = k_values
)
# Set up result list
results_list <- vector("list", nrow(grid))
# Hyperparameter tuning
for (i in seq_len(nrow(grid))) {
# Get the setting
ntree_i <- grid$ntree[i]
k_i     <- grid$k[i]
# Fit the model
fit <- dbarts::bart(
x.train   = x_train,
y.train   = y_train,
x.test    = x_test,
ntree     = ntree_i,
k         = k_i,
ndpost    = ndpost,
nskip     = nskip,
verbose   = FALSE,
keeptrees = TRUE
)
# Get posterior samples -> probabilities via probit link
prob_samples <- pnorm(fit$yhat.test)   # ndpost x n_test
prob_hat     <- colMeans(prob_samples) # posterior mean P(Y = 1 | x)
# Class predictions using 0.5 threshold
class_hat <- ifelse(prob_hat >= 0.5, pos_level, levels(truth)[1])
class_hat <- factor(class_hat, levels = levels(truth))
# Resulting metrics (acc / auc_ expect factor truth)
results_list[[i]] <- data.frame(
ntree = ntree_i,
k     = k_i,
acc   = acc(truth, class_hat),
auc   = auc_(truth, prob_hat)
)
}
results <- do.call(rbind, results_list)
# sort by AUC (best first)
results[order(-results$auc), ]
}
# Train and tune BART Model
set.seed(123)
bart_results_class <- bart_grid_search_class (
train = cls_train,
test = cls_test,
ntree_values = c(50, 100, 200),
k_values = c(1, 2, 3),
ndpost = 1000,
nskip = 1000
)
# highlight best + top 3
cat("Best configuration (by auc):\n")
print(bart_results_class[1, ])
cat("\nTop 3 configurations (by auc):\n")
print(head(bart_results_class, 3))
unlink("~/Documents/Homework/2025 Fall/SDS 4210/Jack_Yang_HW5_cache", recursive = TRUE)
